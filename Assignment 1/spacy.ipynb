{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introduction_doc = nlp(\n",
    "    \"This tutorial is about Natural Language Processing in spaCy.\"\n",
    ")\n",
    "type(introduction_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence detection is the process...\n",
      "This allows you to you...\n"
     ]
    }
   ],
   "source": [
    "about_text = (\n",
    "    \"Sentence detection is the process of locating where sentences start and end in a given text.\" \n",
    "    \"This allows you to you divide a text into linguistically meaningful units.\"\n",
    "    \"spaCy is correctly able to identify the input’s sentences.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "sentences = list(about_doc.sents)\n",
    "len(sentences)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(f\"{sentence[:5]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence detection is the process of locating where sentences start and end in a given text.\n",
      "This allows you to you divide a text into linguistically meaningful units.spaCy is correctly able to identify the input’s sentences.\n"
     ]
    }
   ],
   "source": [
    "ellipsis_text = (\n",
    "    \"Sentence detection is the process of locating where sentences start and end in a given text.\" \n",
    "    \"This allows you to you divide a text into linguistically meaningful units.\"\n",
    "    \"spaCy is correctly able to identify the input’s sentences.\"\n",
    ")\n",
    "\n",
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    \"\"\"Add support to use `...` as a delimiter for sentence detection\"\"\"\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0\n",
      "detection 9\n",
      "is 19\n",
      "the 22\n",
      "process 26\n",
      "of 34\n",
      "locating 37\n",
      "where 46\n",
      "sentences 52\n",
      "start 62\n",
      "and 68\n",
      "end 72\n",
      "in 76\n",
      "a 79\n",
      "given 81\n",
      "text 87\n",
      ". 91\n",
      "This 92\n",
      "allows 97\n",
      "you 104\n",
      "to 108\n",
      "you 111\n",
      "divide 115\n",
      "a 122\n",
      "text 124\n",
      "into 129\n",
      "linguistically 134\n",
      "meaningful 149\n",
      "units.spaCy 160\n",
      "is 172\n",
      "correctly 175\n",
      "able 185\n",
      "to 190\n",
      "identify 193\n",
      "the 202\n",
      "input 206\n",
      "’s 211\n",
      "sentences 214\n",
      ". 223\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "about_text = (\n",
    "    \"Sentence detection is the process of locating where sentences start and end in a given text.\" \n",
    "    \"This allows you to you divide a text into linguistically meaningful units.\"\n",
    "    \"spaCy is correctly able to identify the input’s sentences.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "for token in about_doc:\n",
    "    print (token, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Whitespace  Is Alphanumeric?Is Punctuation?   Is Stop Word?\n",
      "Sentence              True           False             False\n",
      "detection             True           False             False\n",
      "is                    True           False             True\n",
      "the                   True           False             True\n",
      "process               True           False             False\n",
      "of                    True           False             True\n",
      "locating              True           False             False\n",
      "where                 True           False             True\n",
      "sentences             True           False             False\n",
      "start                 True           False             False\n",
      "and                   True           False             True\n",
      "end                   True           False             False\n",
      "in                    True           False             True\n",
      "a                     True           False             True\n",
      "given                 True           False             False\n",
      "text                  True           False             False\n",
      ".                     False          True              False\n",
      "This                  True           False             True\n",
      "allows                True           False             False\n",
      "you                   True           False             True\n",
      "to                    True           False             True\n",
      "you                   True           False             True\n",
      "divide                True           False             False\n",
      "a                     True           False             True\n",
      "text                  True           False             False\n",
      "into                  True           False             True\n",
      "linguistically        True           False             False\n",
      "meaningful            True           False             False\n",
      "units.spaCy           False          False             False\n",
      "is                    True           False             True\n",
      "correctly             True           False             False\n",
      "able                  True           False             False\n",
      "to                    True           False             True\n",
      "identify              True           False             False\n",
      "the                   True           False             True\n",
      "input                 True           False             False\n",
      "’s                    False          False             True\n",
      "sentences             True           False             False\n",
      ".                     False          True              False\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"{\"Text with Whitespace\":22}\"\n",
    "    f\"{\"Is Alphanumeric?\":15}\"\n",
    "    f\"{\"Is Punctuation?\":18}\"\n",
    "    f\"{\"Is Stop Word?\"}\"\n",
    ")\n",
    "for token in about_doc:\n",
    "    print(\n",
    "        f\"{str(token.text_with_ws):22}\"\n",
    "        f\"{str(token.is_alpha):15}\"\n",
    "        f\"{str(token.is_punct):18}\"\n",
    "        f\"{str(token.is_stop)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentences', 'start', 'and', 'end', 'in', 'a', 'given']\n"
     ]
    }
   ],
   "source": [
    "custom_about_text = (\n",
    "    \"Sentence detection is the process of locating where sentences start and end in a given text.\" \n",
    "    \"This allows you to you divide a text into linguistically meaningful units.\"\n",
    "    \"spaCy is correctly able to identify the input’s sentences.\"\n",
    ")\n",
    "\n",
    "print([token.text for token in nlp(custom_about_text)[8:15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentences', 'start', 'and', 'end', 'in', 'a', 'given']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "prefix_re = spacy.util.compile_prefix_regex(\n",
    "    custom_nlp.Defaults.prefixes\n",
    ")\n",
    "suffix_re = spacy.util.compile_suffix_regex(\n",
    "    custom_nlp.Defaults.suffixes\n",
    ")\n",
    "\n",
    "custom_infixes = [r\"@\"]\n",
    "\n",
    "infix_re = spacy.util.compile_infix_regex(\n",
    "    list(custom_nlp.Defaults.infixes) + custom_infixes\n",
    ")\n",
    "\n",
    "custom_nlp.tokenizer = Tokenizer(\n",
    "    nlp.vocab,\n",
    "    prefix_search=prefix_re.search,\n",
    "    suffix_search=suffix_re.search,\n",
    "    infix_finditer=infix_re.finditer,\n",
    "    token_match=None,\n",
    ")\n",
    "\n",
    "custom_tokenizer_about_doc = custom_nlp(custom_about_text)\n",
    "\n",
    "print([token.text for token in custom_tokenizer_about_doc[8:15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yourself\n",
      "hereupon\n",
      "very\n",
      "perhaps\n",
      "'re\n",
      "its\n",
      "thereafter\n",
      "give\n",
      "mostly\n",
      "never\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "len(spacy_stopwords)\n",
    "\n",
    "for stop_word in list(spacy_stopwords)[:10]:\n",
    "    print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence, detection, process, locating, sentences, start, end, given, text, ., allows, divide, text, linguistically, meaningful, units.spaCy, correctly, able, identify, input, sentences, .]\n"
     ]
    }
   ],
   "source": [
    "custom_about_text = (\n",
    "    \"Sentence detection is the process of locating where sentences start and end in a given text.\" \n",
    "    \"This allows you to you divide a text into linguistically meaningful units.\"\n",
    "    \"spaCy is correctly able to identify the input’s sentences.\"\n",
    ")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "about_doc = nlp(custom_about_text)\n",
    "print([token for token in about_doc if not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Sentence : sentence\n",
      "                  is : be\n",
      "            locating : locate\n",
      "           sentences : sentence\n",
      "               given : give\n",
      "                This : this\n",
      "              allows : allow\n",
      "         units.spaCy : units.spacy\n",
      "                  is : be\n",
      "           sentences : sentence\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "conference_help_text = (\n",
    "\"Sentence detection is the process of locating where sentences start and end in a given text.\" \n",
    "    \"This allows you to you divide a text into linguistically meaningful units.\"\n",
    "    \"spaCy is correctly able to identify the input’s sentences.\")\n",
    "conference_help_doc = nlp(conference_help_text)\n",
    "for token in conference_help_doc:\n",
    "    if str(token) != str(token.lemma_):\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOKEN: Sentence\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: detection\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: is\n",
      "=====\n",
      "TAG: VBZ        POS: AUX\n",
      "EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "TOKEN: the\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: process\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: of\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: locating\n",
      "=====\n",
      "TAG: VBG        POS: VERB\n",
      "EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "TOKEN: where\n",
      "=====\n",
      "TAG: WRB        POS: SCONJ\n",
      "EXPLANATION: wh-adverb\n",
      "\n",
      "TOKEN: sentences\n",
      "=====\n",
      "TAG: NNS        POS: NOUN\n",
      "EXPLANATION: noun, plural\n",
      "\n",
      "TOKEN: start\n",
      "=====\n",
      "TAG: VBP        POS: VERB\n",
      "EXPLANATION: verb, non-3rd person singular present\n",
      "\n",
      "TOKEN: and\n",
      "=====\n",
      "TAG: CC         POS: CCONJ\n",
      "EXPLANATION: conjunction, coordinating\n",
      "\n",
      "TOKEN: end\n",
      "=====\n",
      "TAG: VB         POS: VERB\n",
      "EXPLANATION: verb, base form\n",
      "\n",
      "TOKEN: in\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: a\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: given\n",
      "=====\n",
      "TAG: VBN        POS: VERB\n",
      "EXPLANATION: verb, past participle\n",
      "\n",
      "TOKEN: text\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n",
      "\n",
      "TOKEN: This\n",
      "=====\n",
      "TAG: DT         POS: PRON\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: allows\n",
      "=====\n",
      "TAG: VBZ        POS: VERB\n",
      "EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "TOKEN: you\n",
      "=====\n",
      "TAG: PRP        POS: PRON\n",
      "EXPLANATION: pronoun, personal\n",
      "\n",
      "TOKEN: to\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: you\n",
      "=====\n",
      "TAG: PRP        POS: PRON\n",
      "EXPLANATION: pronoun, personal\n",
      "\n",
      "TOKEN: divide\n",
      "=====\n",
      "TAG: VB         POS: VERB\n",
      "EXPLANATION: verb, base form\n",
      "\n",
      "TOKEN: a\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: text\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: into\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: linguistically\n",
      "=====\n",
      "TAG: RB         POS: ADV\n",
      "EXPLANATION: adverb\n",
      "\n",
      "TOKEN: meaningful\n",
      "=====\n",
      "TAG: JJ         POS: ADJ\n",
      "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "TOKEN: units.spaCy\n",
      "=====\n",
      "TAG: JJ         POS: ADJ\n",
      "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "TOKEN: is\n",
      "=====\n",
      "TAG: VBZ        POS: AUX\n",
      "EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "TOKEN: correctly\n",
      "=====\n",
      "TAG: RB         POS: ADV\n",
      "EXPLANATION: adverb\n",
      "\n",
      "TOKEN: able\n",
      "=====\n",
      "TAG: JJ         POS: ADJ\n",
      "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "TOKEN: to\n",
      "=====\n",
      "TAG: TO         POS: PART\n",
      "EXPLANATION: infinitival \"to\"\n",
      "\n",
      "TOKEN: identify\n",
      "=====\n",
      "TAG: VB         POS: VERB\n",
      "EXPLANATION: verb, base form\n",
      "\n",
      "TOKEN: the\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: input\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: ’s\n",
      "=====\n",
      "TAG: POS        POS: PART\n",
      "EXPLANATION: possessive ending\n",
      "\n",
      "TOKEN: sentences\n",
      "=====\n",
      "TAG: NNS        POS: NOUN\n",
      "EXPLANATION: noun, plural\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "about_text = (\n",
    "\"Sentence detection is the process of locating where sentences start and end in a given text.\" \n",
    "    \"This allows you to you divide a text into linguistically meaningful units.\"\n",
    "    \"spaCy is correctly able to identify the input’s sentences.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "for token in about_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "TOKEN: {str(token)}\n",
    "=====\n",
    "TAG: {str(token.tag_):10} POS: {token.pos_}\n",
    "EXPLANATION: {spacy.explain(token.tag_)}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
